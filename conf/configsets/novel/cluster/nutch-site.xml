<?xml version="1.0" ?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl" ?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

    <!-- storage -->
    <property>
        <name>storage.crawl.id</name>
        <value>novel_native_0808</value>
        <description>crawl pages for information/intelligence mining
        </description>
    </property>

    <property>
        <name>storage.data.store.class</name>
        <value>org.apache.gora.hbase.store.HBaseStore</value>
    </property>

    <!-- fetcher -->
    <property>
        <name>fetcher.fetch.mode</name>
        <value>NATIVE</value>
        <description>native, proxy and crowdsourcing</description>
    </property>

    <property>
        <name>fetcher.threads.per.queue</name>
        <value>1</value>
    </property>

    <property>
        <name>fetcher.threads.fetch</name>
        <value>50</value>
    </property>

    <property>
        <name>fetcher.throughput.threshold.pages</name>
        <value>1</value>
        <description>The threshold of minimum pages per second. If the fetcher
            downloads less
            pages per second than the configured threshold, the
            fetcher stops, preventing slow queue's
            from stalling the throughput.
            This threshold must be an integer. This can be useful when
            fetcher.timelimit.mins is hard to determine. The default value of -1
            disables this check.
        </description>
    </property>

    <property>
        <name>fetcher.net.bandwidth.m</name>
        <value>4</value>
        <description>Hardware bandwidth in Mbytes, if exceed the limit,
            slows
            down the task scheduling.
        </description>
    </property>

    <property>
        <name>nutch.master.host</name>
        <value>qiwur.com</value>
        <description>
            A internet ip, hostname, or domain.
            All fetch servers register itself using a internet domain so satellites
            can do tasks from the internet.
        </description>
    </property>

    <property>
        <name>nutch.master.hostname</name>
        <value>galaxyeye</value>
        <description>
            A Intranet access point.
            All slave nutch update proxy
            server list and other resource if any from the master nutch server.
            It must be the host name which is in /etc/hostname since we need to
            check whether it's the host itself.
        </description>
    </property>

    <!-- fetch rules -->

    <property>
        <name>http.useHttp11</name>
        <value>true</value>
    </property>

    <property>
        <name>http.robots.obey</name>
        <value>false</value>
        <description>sorry, we do not obey the robots.txt protocol
        </description>
    </property>

    <property>
        <name>http.agent.name</name>
        <value>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.12 Safari/535.11</value>
        <description></description>
    </property>

    <property>
        <name>http.timeout</name>
        <value>300000</value>
        <description>we have a very long time out setting, it's for a reason
        </description>
    </property>

    <property>
        <name>fetcher.task.timeout</name>
        <value>10m</value>
        <description>fetch thread will exit if no any fetch item for
            fetcher.task.timeout minutes
        </description>
    </property>

    <property>
        <name>http.fetch.max.retry</name>
        <value>3</value>
    </property>

    <property>
        <name>http.content.limit</name>
        <value>1048576</value>
    </property>

    <property>
        <name>parser.skip.truncated</name>
        <value>false</value>
        <description>no truncate actually since we give a very large value for
            http.content.limit
        </description>
    </property>

    <property>
        <name>parser.character.encoding.default</name>
        <value>utf-8</value>
    </property>

    <property>
        <name>db.fetch.interval.default</name>
        <value>25920000</value>
    </property>

    <property>
        <name>db.fetch.interval.max</name>
        <value>25920000</value>
    </property>

    <property>
        <name>db.ignore.external.links</name>
        <value>false</value>
        <description>If true, outlinks leading from a page to external hosts
            will be ignored
        </description>
    </property>

    <property>
        <name>db.ignore.internal.links</name>
        <value>false</value>
    </property>

    <!-- Parsing -->
    <property>
        <name>db.max.anchor.length</name>
        <value>200</value>
        <description>The maximum number of characters permitted in an anchor.
        </description>
    </property>

    <!-- <property> <name>plugin.includes</name> <value>protocol-(http|crowd)|urlfilter-regex|parse-(html)|index-(basic|anchor)|indexer-solr|urlnormalizer-(pass|regex|basic)|scoring-opic</value>
        </property> -->

    <!-- Scoring -->
    <!-- This is a temporary solution to indicate important links -->
    <property>
        <name>db.score.important.links</name>
        <value>product,item,detail,view,show,good,store,activity</value>
        <description></description>
    </property>

    <!-- Generate -->
    <property>
        <name>generator.map.threads.per.task</name>
        <value>50</value>
        <description></description>
    </property>

    <!-- Solr Index -->
    <property>
        <name>solr.zookeeper.hosts</name>
        <value>iZ235p20xpvZ:2181,iZ237ax7rsqZ:2181,iZ23ocq7jaaZ:2181</value>
        <description>Zookeeper String</description>
    </property>
    <property>
        <name>solr.collection</name>
        <value>novel_native_0808</value>
        <description>solr collection</description>
    </property>

</configuration>
