#!/usr/bin/env bash
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# The Nutch command script

bin=`dirname "$0"`
bin=`cd "$bin">/dev/null; pwd`

# This will set NUTCH_HOME, etc.
 . "$bin"/nutch-config.sh

in_dev_env=false
if [ -n "${DEV_NUTCH_HOME}" ]; then
  in_dev_env=true
fi

# if no args specified, show usage
if [ $# = 0 ]; then
  echo "Usage: nutch COMMAND"
  echo "where COMMAND is one of:"
  echo " master    	run nutch master service"
  echo " inject		inject new urls into the database"
  echo " hostinject     creates or updates an existing host table from a text file"
  echo " generate 	generate new batches to fetch from crawl db"
  echo " fetch 		fetch URLs marked during generate"
  echo " parse 		parse URLs marked during fetch"
  echo " updatedb 	update web table after parsing"
  echo " updatehostdb   update host table after parsing"
  echo " readdb 	read/dump records from page database"
  echo " readhostdb     display entries from the hostDB"
  echo " index          run the plugin-based indexer on parsed batches"
  echo " elasticindex   run the elasticsearch indexer - DEPRECATED use the index command instead"
  echo " solrindex 	run the solr indexer on parsed batches - DEPRECATED use the index command instead"
  echo " solrdedup 	remove duplicates from solr"
  echo " solrclean      remove HTTP 301 and 404 documents from solr - DEPRECATED use the clean command instead"
  echo " clean          remove HTTP 301 and 404 documents and duplicates from indexing backends configured via plugins"
  echo " parsechecker   check the parser for a given url"
  echo " indexchecker   check the indexing filters for a given url"
  echo " plugin 	load a plugin and run one of its classes main()"
  echo " webapp         run a local Nutch web application"
  echo " junit         	runs the given JUnit test"
  echo " or"
  echo " CLASSNAME 	run the class named CLASSNAME"
  echo "Most commands print help when invoked w/o parameters."
  exit 1
fi

# get arguments
COMMAND=$1
shift

JAVA="$JAVA_HOME/bin/java"
# JAVA_HEAP_MAX=-Xmx1000m

# CLASSPATH initially contains $NUTCH_CONF_DIR, or defaults to $NUTCH_HOME/conf
CLASSPATH="${NUTCH_CONF_DIR:=$NUTCH_HOME/conf}"
CLASSPATH="${CLASSPATH}:$JAVA_HOME/lib/tools.jar"

# so that filenames w/ spaces are handled correctly in loops below
IFS=

# add libs to CLASSPATH

if [ $NUTCH_RUNTIME_MODE == "LOCAL" ]; then
  for f in "$NUTCH_HOME"/lib/*.jar; do
    if [ -f $f ]; then
      CLASSPATH="${CLASSPATH}:$f"
    fi
  done
  # local runtime
  # add plugins to classpath
  if [ -d "$NUTCH_HOME/plugins" ]; then
     CLASSPATH="${NUTCH_HOME}:${CLASSPATH}"
  fi
fi

# restore ordinary behaviour
unset IFS

# figure out which class to run
if [ "$COMMAND" = "crawl" ] ; then
  echo "Command $COMMAND is deprecated, please use bin/crawl instead"
  exit -1
elif [ "$COMMAND" = "master" ] ; then
  CLASS=org.apache.nutch.api.NutchServer
elif [ "$COMMAND" = "inject" ] ; then
  CLASS=org.apache.nutch.crawl.InjectorJob
elif [ "$COMMAND" = "hostinject" ] ; then
  CLASS=org.apache.nutch.host.HostInjectorJob
elif [ "$COMMAND" = "generate" ] ; then
  CLASS=org.apache.nutch.crawl.GeneratorJob
elif [ "$COMMAND" = "fetch" ] ; then
  CLASS=org.apache.nutch.fetcher.FetcherJob
elif [ "$COMMAND" = "parse" ] ; then
  CLASS=org.apache.nutch.parse.ParserJob
elif [ "$COMMAND" = "updatedb" ] ; then
  CLASS=org.apache.nutch.crawl.DbUpdaterJob
elif [ "$COMMAND" = "updatehostdb" ] ; then
  CLASS=org.apache.nutch.host.HostDbUpdateJob
elif [ "$COMMAND" = "readdb" ] ; then
  CLASS=org.apache.nutch.crawl.WebTableReader
elif [ "$COMMAND" = "readhostdb" ] ; then
  CLASS=org.apache.nutch.host.HostDbReader
elif [ "$COMMAND" = "elasticindex" ] ; then
  CLASS=org.apache.nutch.indexer.elastic.ElasticIndexerJob
elif [ "$COMMAND" = "solrindex" ] ; then
  CLASS="org.apache.nutch.indexer.IndexingJob -Dsolr.server.url=$1"
  shift
elif [ "$COMMAND" = "index" ] ; then
  CLASS=org.apache.nutch.indexer.IndexingJob
elif [ "$COMMAND" = "solrdedup" ] ; then
  CLASS=org.apache.nutch.indexer.solr.SolrDeleteDuplicates
elif [ "$COMMAND" = "solrclean" ] ; then
  CLASS="org.apache.nutch.indexer.CleaningJob -Dsolr.server.url=$2 $1"
  shift; shift
elif [ "$COMMAND" = "clean" ] ; then
  CLASS=org.apache.nutch.indexer.CleaningJob
elif [ "$COMMAND" = "parsechecker" ] ; then
  CLASS=org.apache.nutch.parse.ParserChecker
elif [ "$COMMAND" = "indexchecker" ] ; then
  CLASS=org.apache.nutch.indexer.IndexingFiltersChecker
elif [ "$COMMAND" = "plugin" ] ; then
  CLASS=org.apache.nutch.plugin.PluginRepository
elif [ "$COMMAND" = "webapp" ] ; then
  CLASS=org.apache.nutch.webui.NutchUiServer
elif [ "$COMMAND" = "junit" ] ; then
  CLASSPATH="$CLASSPATH:$NUTCH_HOME/test/classes/"
  CLASS=org.junit.runner.JUnitCore
else
  CLASS=$COMMAND
fi

# export NUTCH_LOG_PREFIX=nutch-$NUTCH_IDENT_STRING-$COMMAND-$HOSTNAME
export NUTCH_LOG_PREFIX=nutch-$NUTCH_IDENT_STRING-all-$HOSTNAME
export NUTCH_LOGFILE=$NUTCH_LOG_PREFIX.log
export NUTCH_LOGOUT=$NUTCH_LOG_PREFIX.out

# distribute mode
if [ $NUTCH_RUNTIME_MODE == "DISTRIBUTE" ]; then
 # check that hadoop can be found on the path
 if [ $(which hadoop | wc -l ) -eq 0 ]; then
    echo "Can't find Hadoop executable. Add HADOOP_HOME/bin to the path or run in local mode."
    exit -1;
 fi
 # distributed mode
 EXEC_CALL=(hadoop jar "$NUTCH_JOB")
 exec "${EXEC_CALL[@]}" $CLASS "$@"
 exit 0
fi

# local mode
loglog="${NUTCH_LOG_DIR}/${NUTCH_LOGFILE}"
logout="${NUTCH_LOG_DIR}/${NUTCH_LOGOUT}"
logcmd="${NUTCH_LOG_DIR}/last-cmd-name"

NUTCH_OPTS=($NUTCH_OPTS -Dhadoop.log.dir=$NUTCH_LOG_DIR)
NUTCH_OPTS=("${NUTCH_OPTS[@]}" -Dhadoop.log.file=$NUTCH_LOGFILE)
NUTCH_OPTS=("${NUTCH_OPTS[@]}" -Dnutch.home.dir=$NUTCH_HOME)
NUTCH_OPTS=("${NUTCH_OPTS[@]}" -Dnutch.id.str=$NUTCH_IDENT_STRING)
NUTCH_OPTS=("${NUTCH_OPTS[@]}" -Dnutch.root.logger=${NUTCH_ROOT_LOGGER:-INFO,console})

export CLASSPATH

# fix for the external Xerces lib issue with SAXParserFactory
NUTCH_OPTS=(-Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl "${NUTCH_OPTS[@]}")
EXEC_CALL=("$JAVA" -Dproc_$COMMAND -XX:OnOutOfMemoryError="kill -9 %p" $JAVA_HEAP_MAX "${NUTCH_OPTS[@]}")

# run it
MESSAGE="\n\n
============Nutch Rumtime================\n
`date` Starting $COMMAND on `hostname`\n\n
............Nutch Options..............\n
$NUTCH_OPTS\n\n
............Nutch CLASSPATH............\n
$CLASSPATH\n\n
"

echo -e $MESSAGE >> $logout 2>&1
ulimit -a >> $logout 2>&1
echo $COMMAND > $logcmd

echo "Working direcotry : `pwd`"
echo "Nutch home : $NUTCH_HOME"
[[ -d $NUTCH_SRC_HOME ]] && echo "Develop mode, nutch src dir : $NUTCH_SRC_HOME"
echo "Nutch version : `cat $NUTCH_HOME/VERSION`"
echo "Log file : $loglog"

echo "${EXEC_CALL[@]}" $CLASS "$@"
exec "${EXEC_CALL[@]}" $CLASS "$@"
